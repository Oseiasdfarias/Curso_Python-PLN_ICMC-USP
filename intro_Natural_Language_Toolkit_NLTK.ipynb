{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro-Natural_Language_Toolkit_NLTK.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oseiasdfarias/Curso_Python-PLN_ICMC-USP/blob/main/intro_Natural_Language_Toolkit_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqtwfvvAweVJ"
      },
      "source": [
        "# **Python para Processamento de Linguagem Natural ICMC|USP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGa5crM_wRqj"
      },
      "source": [
        "## **Instalando o NLTK**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEdUVJmYwDmi",
        "outputId": "23d10b13-3042-430f-82b3-a61d23c1b67d"
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r24Ej-2Ew-ed"
      },
      "source": [
        "## Baixando dados extras\n",
        "\n",
        "\n",
        ">> ####  Obs:1° Digite \"d\" e click enter\n",
        ">> ####  Obs:2° Digite \"all\" e click enter\n",
        ">> ####  Obs:3° Digite \"q\" e click enter para sair\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHbQKD5ExPkX"
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuIr1m3j1MLH"
      },
      "source": [
        "\n",
        "## **Primeiros Passos com o NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-vJSopg0TGF"
      },
      "source": [
        "### **Listar as palavras existente no Corpus Mac-Morpho**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_hMzgJSyakM",
        "outputId": "ad8aa93d-9137-4629-e4ca-e4079ee8db45"
      },
      "source": [
        "nltk.corpus.mac_morpho.words()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jersei', 'atinge', 'média', 'de', 'Cr$', '1,4', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgSdAGgO06I6"
      },
      "source": [
        "### **Listar uma ou mais palavras existente no Corpus Mac-Morpho**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VuT8SQtm1AWT",
        "outputId": "a1283a3b-e37c-42bb-a13b-50a5c3dd72aa"
      },
      "source": [
        "nltk.corpus.mac_morpho.words()[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jersei'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUU_xEbL1DW_",
        "outputId": "36610ccb-10e4-4eb5-d7d8-376964ab5558"
      },
      "source": [
        "nltk.corpus.mac_morpho.words()[3:7]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de', 'Cr$', '1,4', 'milhão']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Ioqry00eGO"
      },
      "source": [
        "### **Listar sentenças existente no Corpus Mac-Morpho**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxcmlVtRz0UQ",
        "outputId": "0b82b477-a586-457e-f73d-8bf65a178d0b"
      },
      "source": [
        "nltk.corpus.mac_morpho.sents()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Jersei', 'atinge', 'média', 'de', 'Cr$', '1,4', 'milhão', 'em', 'a', 'venda', 'de', 'a', 'Pinhal', 'em', 'São', 'Paulo'], ['Programe', 'sua', 'viagem', 'a', 'a', 'Exposição', 'Nacional', 'do', 'Zebu', ',', 'que', 'começa', 'dia', '25'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wx3SmTm0mhq"
      },
      "source": [
        "### **Listar uma ou mais sentença existente no Corpus Mac-Morpho**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdASeLxk0Nq2",
        "outputId": "38a7b436-27e8-40be-f724-fb80e2eb50c6"
      },
      "source": [
        "nltk.corpus.mac_morpho.sents()[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jersei',\n",
              " 'atinge',\n",
              " 'média',\n",
              " 'de',\n",
              " 'Cr$',\n",
              " '1,4',\n",
              " 'milhão',\n",
              " 'em',\n",
              " 'a',\n",
              " 'venda',\n",
              " 'de',\n",
              " 'a',\n",
              " 'Pinhal',\n",
              " 'em',\n",
              " 'São',\n",
              " 'Paulo']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCBnskde0vQI",
        "outputId": "81a1f7dc-62cc-43fa-9ae5-0dea6dea7365"
      },
      "source": [
        "nltk.corpus.mac_morpho.sents()[0:3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Jersei',\n",
              "  'atinge',\n",
              "  'média',\n",
              "  'de',\n",
              "  'Cr$',\n",
              "  '1,4',\n",
              "  'milhão',\n",
              "  'em',\n",
              "  'a',\n",
              "  'venda',\n",
              "  'de',\n",
              "  'a',\n",
              "  'Pinhal',\n",
              "  'em',\n",
              "  'São',\n",
              "  'Paulo'],\n",
              " ['Programe',\n",
              "  'sua',\n",
              "  'viagem',\n",
              "  'a',\n",
              "  'a',\n",
              "  'Exposição',\n",
              "  'Nacional',\n",
              "  'do',\n",
              "  'Zebu',\n",
              "  ',',\n",
              "  'que',\n",
              "  'começa',\n",
              "  'dia',\n",
              "  '25'],\n",
              " ['Safra',\n",
              "  'recorde',\n",
              "  'e',\n",
              "  'disponibilidade',\n",
              "  'de',\n",
              "  'crédito',\n",
              "  'ativam',\n",
              "  'vendas',\n",
              "  'de',\n",
              "  'máquinas',\n",
              "  'agrícolas']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGxDbvLu1xL4"
      },
      "source": [
        "### **Acessando as palavras com suas etiquetas(targs)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocpX0eYK0zkG",
        "outputId": "ff92a2c1-19c1-41d8-e831-d979b0fbe1f3"
      },
      "source": [
        "nltk.corpus.mac_morpho.tagged_words()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84zTHz-C2PUy"
      },
      "source": [
        "### **Acessando os sentenças com suas etiquetas(targs)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-akemswU2EjW",
        "outputId": "e03836fb-f513-416a-ad7e-d3a716cf5134"
      },
      "source": [
        "nltk.corpus.mac_morpho.tagged_sents()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ('de', 'PREP'), ('Cr$', 'CUR'), ('1,4', 'NUM'), ('milhão', 'N'), ('em', 'PREP|+'), ('a', 'ART'), ('venda', 'N'), ('de', 'PREP|+'), ('a', 'ART'), ('Pinhal', 'NPROP'), ('em', 'PREP'), ('São', 'NPROP'), ('Paulo', 'NPROP')], [('Programe', 'V'), ('sua', 'PROADJ'), ('viagem', 'N'), ('a', 'PREP|+'), ('a', 'ART'), ('Exposição', 'NPROP'), ('Nacional', 'NPROP'), ('do', 'NPROP'), ('Zebu', 'NPROP'), (',', ','), ('que', 'PRO-KS-REL'), ('começa', 'V'), ('dia', 'N'), ('25', 'N|AP')], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9C-9DYZ2ioM",
        "outputId": "e9939d55-81f6-4a18-ae88-ab8a0ec1fad2"
      },
      "source": [
        "nltk.corpus.mac_morpho.tagged_sents()[0]\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Jersei', 'N'),\n",
              " ('atinge', 'V'),\n",
              " ('média', 'N'),\n",
              " ('de', 'PREP'),\n",
              " ('Cr$', 'CUR'),\n",
              " ('1,4', 'NUM'),\n",
              " ('milhão', 'N'),\n",
              " ('em', 'PREP|+'),\n",
              " ('a', 'ART'),\n",
              " ('venda', 'N'),\n",
              " ('de', 'PREP|+'),\n",
              " ('a', 'ART'),\n",
              " ('Pinhal', 'NPROP'),\n",
              " ('em', 'PREP'),\n",
              " ('São', 'NPROP'),\n",
              " ('Paulo', 'NPROP')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Wtwb7K3_tI"
      },
      "source": [
        "### **Tokenizando textos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Zzy7AI2qBI"
      },
      "source": [
        "texto = \"\"\"Com um passe de Eli Manning para Plaxico Burress a 39 \n",
        "segundos do fim, o New York Giants anotou o touchdown decisivo e \n",
        "derrubou o favorito New England Patriots por 17 a 14 neste domingo, \n",
        "em Glendale, no Super Bowl XLII.\"\"\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjibFe0-4MVW",
        "outputId": "18d2048a-5f98-404a-eae5-77d3f572e1be"
      },
      "source": [
        "nltk.word_tokenize(texto)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Com',\n",
              " 'um',\n",
              " 'passe',\n",
              " 'de',\n",
              " 'Eli',\n",
              " 'Manning',\n",
              " 'para',\n",
              " 'Plaxico',\n",
              " 'Burress',\n",
              " 'a',\n",
              " '39',\n",
              " 'segundos',\n",
              " 'do',\n",
              " 'fim',\n",
              " ',',\n",
              " 'o',\n",
              " 'New',\n",
              " 'York',\n",
              " 'Giants',\n",
              " 'anotou',\n",
              " 'o',\n",
              " 'touchdown',\n",
              " 'decisivo',\n",
              " 'e',\n",
              " 'derrubou',\n",
              " 'o',\n",
              " 'favorito',\n",
              " 'New',\n",
              " 'England',\n",
              " 'Patriots',\n",
              " 'por',\n",
              " '17',\n",
              " 'a',\n",
              " '14',\n",
              " 'neste',\n",
              " 'domingo',\n",
              " ',',\n",
              " 'em',\n",
              " 'Glendale',\n",
              " ',',\n",
              " 'no',\n",
              " 'Super',\n",
              " 'Bowl',\n",
              " 'XLII',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYwoRriE5ndH"
      },
      "source": [
        "### **Regexp no NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sU805_28PDV"
      },
      "source": [
        "### **Retirando pontuações do texto com o Módulo RegexpTokenizer do NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZyoPjx4WGF"
      },
      "source": [
        "from nltk import RegexpTokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTynLaHA6An1"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(texto) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvBZ2l__7PXg",
        "outputId": "9864e7fa-c520-43f3-df75-d6376d585e97"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Com',\n",
              " 'um',\n",
              " 'passe',\n",
              " 'de',\n",
              " 'Eli',\n",
              " 'Manning',\n",
              " 'para',\n",
              " 'Plaxico',\n",
              " 'Burress',\n",
              " 'a',\n",
              " '39',\n",
              " 'segundos',\n",
              " 'do',\n",
              " 'fim',\n",
              " 'o',\n",
              " 'New',\n",
              " 'York',\n",
              " 'Giants',\n",
              " 'anotou',\n",
              " 'o',\n",
              " 'touchdown',\n",
              " 'decisivo',\n",
              " 'e',\n",
              " 'derrubou',\n",
              " 'o',\n",
              " 'favorito',\n",
              " 'New',\n",
              " 'England',\n",
              " 'Patriots',\n",
              " 'por',\n",
              " '17',\n",
              " 'a',\n",
              " '14',\n",
              " 'neste',\n",
              " 'domingo',\n",
              " 'em',\n",
              " 'Glendale',\n",
              " 'no',\n",
              " 'Super',\n",
              " 'Bowl',\n",
              " 'XLII']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl3LNU758oVO"
      },
      "source": [
        "### **Retirando pontuações e números do texto com o Módulo RegexpTokenizer do NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBuQSvyC7Z0L",
        "outputId": "5f12b5ea-4022-429f-a64e-a311c0f1f713"
      },
      "source": [
        "  tokenizer = RegexpTokenizer(r'[a-zA-Z]\\w+')\n",
        "  tokens = tokenizer.tokenize(texto)\n",
        "  tokens"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Com',\n",
              " 'um',\n",
              " 'passe',\n",
              " 'de',\n",
              " 'Eli',\n",
              " 'Manning',\n",
              " 'para',\n",
              " 'Plaxico',\n",
              " 'Burress',\n",
              " 'segundos',\n",
              " 'do',\n",
              " 'fim',\n",
              " 'New',\n",
              " 'York',\n",
              " 'Giants',\n",
              " 'anotou',\n",
              " 'touchdown',\n",
              " 'decisivo',\n",
              " 'derrubou',\n",
              " 'favorito',\n",
              " 'New',\n",
              " 'England',\n",
              " 'Patriots',\n",
              " 'por',\n",
              " 'neste',\n",
              " 'domingo',\n",
              " 'em',\n",
              " 'Glendale',\n",
              " 'no',\n",
              " 'Super',\n",
              " 'Bowl',\n",
              " 'XLII']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo_bkblV8IDi"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGiNKIIQ9X99"
      },
      "source": [
        "### **Verificando a Frequência de palavras em um texto**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOhoV2VN9f3A",
        "outputId": "b1a292db-3ba1-44f9-fe81-afb912e90be0"
      },
      "source": [
        "tokens = nltk.word_tokenize(texto)\n",
        "frequencia = nltk.FreqDist(tokens)\n",
        "frequencia.most_common(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 3),\n",
              " ('o', 3),\n",
              " ('a', 2),\n",
              " ('New', 2),\n",
              " ('Com', 1),\n",
              " ('um', 1),\n",
              " ('passe', 1),\n",
              " ('de', 1),\n",
              " ('Eli', 1),\n",
              " ('Manning', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCTdIAnlAIBk"
      },
      "source": [
        "### **Trabalhando com textos maiores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHa-4AHx-LW7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "adff913c-a460-411b-8c36-847bbc97d5f4"
      },
      "source": [
        "corpus = open(\"/content/drive/MyDrive/Curso_PLN_USP/arquivo2.txt\").read()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3828370d7e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Curso_PLN_USP/arquivo2.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Curso_PLN_USP/arquivo2.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcOgZggjAWPh"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww1wGwPTAZfe"
      },
      "source": [
        "  # Cria uma regex que pega apenas as palavras de um texto\n",
        "  tokenizer = RegexpTokenizer(r'[a-zA-Z]\\w+')\n",
        "  tokens = tokenizer.tokenize(corpus)\n",
        "\n",
        "\n",
        "  # transformando as palavras em minúsculas\n",
        "  nova_lista = []\n",
        "  for token in tokens:\n",
        "    nova_lista.append(token.lower())\n",
        "\n",
        "\n",
        "  # Conta a quantidade de vezes que a palavra se repete no texto\n",
        "  frequencia = nltk.FreqDist(nova_lista)\n",
        "  frequencia.most_common(10)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t06ZUsSRRaB"
      },
      "source": [
        "### **Retirando palavras irrelevantes do tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da22-LscQ3eC"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
        "stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2v4-CrlRoZD"
      },
      "source": [
        "  # Cria uma regex que pega apenas as palavras de um texto\n",
        "  tokenizer = RegexpTokenizer(r'[a-zA-Z]\\w+')\n",
        "  tokens = tokenizer.tokenize(corpus)\n",
        "\n",
        "\n",
        "  # transformando as palavras em minúsculas\n",
        "  nova_lista = []\n",
        "  for token in tokens:\n",
        "    # Filtrando as palavras  irrelevantes do texto e adicionando apenas as relevantes na nova lista\n",
        "    if token.lower() not in stopwords:\n",
        "      nova_lista.append(token.lower())\n",
        "  \n",
        "\n",
        "  # Conta a quantidade de vezes que a palavra se repete no texto\n",
        "  frequencia = nltk.FreqDist(nova_lista)\n",
        "  frequencia.most_common(10)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chjJ1bHoTkDe"
      },
      "source": [
        "### **Usando List Comprehensions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6T9NJOYS8A5"
      },
      "source": [
        "  # Cria uma regex que pega apenas as palavras de um texto\n",
        "  tokenizer = RegexpTokenizer(r'[a-zA-Z]\\w+')\n",
        "  tokens = tokenizer.tokenize(corpus)\n",
        "\n",
        "\n",
        "  # transformando as palavras em minúsculas Usando List Comprehensions\n",
        "  nova_lista = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
        "  #for token in tokens:\n",
        "    # Filtrando as palavras  irrelevantes do texto e adicionando apenas as relevantes na nova lista\n",
        "  #  if token.lower() not in stopwords:\n",
        "  #    nova_lista.append(token.lower())\n",
        "  \n",
        "\n",
        "  # Conta a quantidade de vezes que a palavra se repete no texto\n",
        "  frequencia = nltk.FreqDist(nova_lista)\n",
        "  frequencia.most_common(10)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}